{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-GlgO5WBOYeF"
   },
   "source": [
    "# Demo: Using BertViz To Detect Bias\n",
    "\n",
    "Auto-regressive models trained on data created by human beings (e.g., data from the internet) will exhibit many of the same biases of those human beings. Thus, being able to visualize what's happening inside transformers is important to understanding this bias. One tool for visualizing attention is [BertViz](https://github.com/jessevig/bertviz?tab=readme-ov-file#self-attention-models-bert-gpt-2-etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9thTgP1AKYii"
   },
   "source": [
    "## The doctor asked the nurse...\n",
    "\n",
    "Two sentences are run through the auto-regressive GPT2 model:\n",
    "\n",
    "* \"The doctor asked the nurse a question. She\"\n",
    "* \"The doctor asked the nurse a question. He\"\n",
    "\n",
    "We notice that the attention head #10 in the 5th layer shows the pronouns \"She\" and \"He\" attending to the words \"nurse\" and \"doctor\", respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, utils\n",
    "\n",
    "utils.logging.set_verbosity_error()  # Suppress standard warnings\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = AutoModel.from_pretrained(\"gpt2\", output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertviz import head_view\n",
    "\n",
    "inputs = tokenizer.encode(\n",
    "    \"The doctor asked the nurse a question. She\", return_tensors=\"pt\"\n",
    ")\n",
    "outputs = model(inputs)\n",
    "attention = outputs[-1]\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[0])\n",
    "\n",
    "head_view(attention, tokens, layer=5, heads=[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode(\n",
    "    \"The doctor asked the nurse a question. He\", return_tensors=\"pt\"\n",
    ")\n",
    "outputs = model(inputs)\n",
    "attention = outputs[-1]\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[0])\n",
    "\n",
    "head_view(attention, tokens, layer=5, heads=[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The teacher asked the inspector...\n",
    "\n",
    "A similar analysis on the following two sentences can be made:\n",
    "\n",
    "* \"The teacher asked the inspector if the school was structurally sound. He\"\n",
    "* \"The teacher asked the inspector if the school was structurally sound. She\"\n",
    "\n",
    "In this case, the attention mechanism shows \"He\" attending to both teacher and inspector more or less equally but \"She\" attends to \"teacher\" disproportionately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode(\n",
    "    \"The teacher asked the inspector if the school was structurally sound. He\",\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "outputs = model(inputs)\n",
    "attention = outputs[-1]\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[0])\n",
    "\n",
    "head_view(attention, tokens, layer=5, heads=[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode(\n",
    "    \"The teacher asked the inspector if the school was structurally sound. She\",\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "outputs = model(inputs)\n",
    "attention = outputs[-1]\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[0])\n",
    "\n",
    "head_view(attention, tokens, layer=5, heads=[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful Links:\n",
    "* [BertViz Website](https://github.com/jessevig/bertviz)\n",
    "* [BertViz Paper](https://aclanthology.org/P19-3007.pdf)\n",
    "* [BertViz Colab Tutorial](https://colab.research.google.com/drive/1hXIQ77A4TYS4y3UthWF-Ci7V7vVUoxmQ?usp=sharing)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
